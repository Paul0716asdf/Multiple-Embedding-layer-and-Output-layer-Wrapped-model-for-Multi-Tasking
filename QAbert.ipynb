{"cells":[{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-03-12T06:12:42.707362Z","iopub.status.busy":"2023-03-12T06:12:42.706399Z","iopub.status.idle":"2023-03-12T06:12:42.719853Z","shell.execute_reply":"2023-03-12T06:12:42.718694Z","shell.execute_reply.started":"2023-03-12T06:12:42.707316Z"},"id":"DfPP69sn93Ee","trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","import torch\n","\n","from transformers import BertTokenizer\n","\n","from typing import *\n","\n","from MEOW_Models import QA_models, MT_models\n","from MEOW_Utils import QA_utils, MT_utils\n","\n","DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","BATCH_SIZE = 4\n","EPOCH_NUM = 10\n","INPUT_FILE_PATH = r'C:\\Users\\Administrator\\codeblocks_workspace\\MEOW\\train-v2.0.json'\n","PRETRAINED_MODULE_NAME = 'bert-base-uncased'"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-03-12T06:12:44.989700Z","iopub.status.busy":"2023-03-12T06:12:44.989285Z","iopub.status.idle":"2023-03-12T06:12:55.952908Z","shell.execute_reply":"2023-03-12T06:12:55.951673Z","shell.execute_reply.started":"2023-03-12T06:12:44.989651Z"},"id":"8I7oqT9NBAsd","outputId":"89fbeea8-175a-4cde-8ab2-5f8df087f195","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Reading the json file\n","processing...\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\Administrator\\codeblocks_workspace\\MEOW\\MEOW_Utils\\MT_utils.py:100: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead.\n","  js = pd.io.json.json_normalize(file , record_path )\n","c:\\Users\\Administrator\\codeblocks_workspace\\MEOW\\MEOW_Utils\\MT_utils.py:101: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead.\n","  m = pd.io.json.json_normalize(file, record_path[:-1])\n","c:\\Users\\Administrator\\codeblocks_workspace\\MEOW\\MEOW_Utils\\MT_utils.py:102: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead.\n","  r = pd.io.json.json_normalize(file,record_path[:-2])\n","c:\\Users\\Administrator\\codeblocks_workspace\\MEOW\\MEOW_Utils\\MT_utils.py:109: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only.\n","  main = pd.concat([ m[['id','question','context']].set_index('id'),js.set_index('q_idx')],1,sort=False).reset_index()\n"]},{"name":"stdout","output_type":"stream","text":["shape of the dataframe is (130319, 6)\n","Done\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\Administrator\\codeblocks_workspace\\MEOW\\MEOW_Utils\\MT_utils.py:137: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_train['answer_start'] = df_train['answer_start'].apply(lambda x : -1 if np.isnan(x) else int(x))\n","c:\\Users\\Administrator\\codeblocks_workspace\\MEOW\\MEOW_Utils\\MT_utils.py:138: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_train['text'] = df_train['text'].apply(lambda x : x if type(x) is str else '')\n","c:\\Users\\Administrator\\codeblocks_workspace\\MEOW\\MEOW_Utils\\MT_utils.py:140: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_train['TKstart'] = pd.Series([0] * len(df_train))\n","c:\\Users\\Administrator\\codeblocks_workspace\\MEOW\\MEOW_Utils\\MT_utils.py:141: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_train['TKend'] = pd.Series([0] * len(df_train))\n","c:\\Users\\Administrator\\codeblocks_workspace\\MEOW\\MEOW_Utils\\MT_utils.py:144: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_train['TKstart'][i], df_train['TKend'][i] = count_the_TKbeg_and_TKend(df_train.iloc[i]['context'], df_train.iloc[i]['answer_start'], df_train.iloc[i]['text'], tokenizer)\n"]}],"source":["#處理好 dataframe\n","tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODULE_NAME)\n","df_train = MT_utils.get_SQuAD_df(INPUT_FILE_PATH, tokenizer)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-03-12T07:35:19.879696Z","iopub.status.busy":"2023-03-12T07:35:19.878778Z","iopub.status.idle":"2023-03-12T07:35:21.394274Z","shell.execute_reply":"2023-03-12T07:35:21.393139Z","shell.execute_reply.started":"2023-03-12T07:35:19.879646Z"},"id":"PvUgPNFEBcia","outputId":"ba23185a-d01f-42cf-deea-d13e299f27c6","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertWithoutEmbedding: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertWithoutEmbedding from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertWithoutEmbedding from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["#處理好dataset dataloader model等等\n","\n","bert_model = MT_models.BertWithoutEmbedding.from_pretrained(PRETRAINED_MODULE_NAME)\n","GETEMBEDDING_helper =  MT_utils.get_bert_element(bertmodel=bert_model)\n","embedding_layer = GETEMBEDDING_helper.get_copy_embeddings_layer()\n","\n","train_dataset = QA_utils.QAdataset(df_train, tokenizer=tokenizer)\n","train_loader = QA_utils.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=QA_utils.collate_batch)\n","\n","QA_model = QA_models.Bert_QA(model=bert_model, embedding_layer=embedding_layer, device=DEVICE)\n","QA_model.to(DEVICE)\n","\n","EPOCH_NUM = 10\n","optimizer = torch.optim.SGD(QA_model.parameters(), lr=0.001, momentum=0.9)\n","# optimizer = torch.optim.Adam(QA_model.parameters(), lr=0.001, betas=(0.88, 0.95), eps=1e-08)\n","\n","H = {\n","    \"train_loss\": [],\n","    \"train_acc\": [],\n","    \"val_loss\":[],\n","    \"val_acc\": []\n","    }"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"execution":{"iopub.execute_input":"2023-03-12T07:35:23.943599Z","iopub.status.busy":"2023-03-12T07:35:23.942880Z","iopub.status.idle":"2023-03-12T07:36:54.746340Z","shell.execute_reply":"2023-03-12T07:36:54.745130Z","shell.execute_reply.started":"2023-03-12T07:35:23.943552Z"},"id":"ANXk7YP4BeuB","outputId":"1c8fdf98-cfcd-44e9-d6f5-6df336f63d9a","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["the 1 iter :\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32mc:\\Users\\Administrator\\codeblocks_workspace\\MEOW\\QAbert.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Administrator/codeblocks_workspace/MEOW/QAbert.ipynb#W3sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m mask \u001b[39m=\u001b[39m mask\u001b[39m.\u001b[39mto(DEVICE)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Administrator/codeblocks_workspace/MEOW/QAbert.ipynb#W3sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m token \u001b[39m=\u001b[39m token\u001b[39m.\u001b[39mto(DEVICE)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Administrator/codeblocks_workspace/MEOW/QAbert.ipynb#W3sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m loss \u001b[39m=\u001b[39m QA_model(input_ids, mask, token, SEPind, Start_pos, End_pos)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Administrator/codeblocks_workspace/MEOW/QAbert.ipynb#W3sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# print(loss.item())\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Administrator/codeblocks_workspace/MEOW/QAbert.ipynb#W3sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n","File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[1;32mc:\\Users\\Administrator\\codeblocks_workspace\\MEOW\\MEOW_Models\\QA_models.py:45\u001b[0m, in \u001b[0;36mBert_QA.forward\u001b[1;34m(self, input_ids, attention_mask, token, SEPind, start_pos, end_pos)\u001b[0m\n\u001b[0;32m     42\u001b[0m correct_num \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     44\u001b[0m mtx \u001b[39m=\u001b[39m get_retrieve_context_matrix(SEPind, last_hidden_layer\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m), last_hidden_layer\u001b[39m.\u001b[39msize(\u001b[39m2\u001b[39m))\n\u001b[1;32m---> 45\u001b[0m mtx \u001b[39m=\u001b[39m mtx\u001b[39m.\u001b[39;49mto(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice)\n\u001b[0;32m     47\u001b[0m context_LHL \u001b[39m=\u001b[39m last_hidden_layer \u001b[39m*\u001b[39m mtx   \u001b[39m#last hidden layer\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[39m# 錯誤寫法\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[39m# context_LHL = [last_hidden_layer[i][0:SEPind[i]] for i in range(BATCH_SIZE)] # 現在是一個tensor的list\u001b[39;00m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# 訓練\n","\n","for epoch in range(EPOCH_NUM):\n","    print(\"the {:d} iter :\".format(epoch+1))\n","\n","    QA_model.train()\n","    training_loss = 0.0\n","    training_correct = 0.0\n","\n","    for data in train_loader:\n","        input_ids, mask, token, SEPind, Start_pos, End_pos = data\n","        \n","        # input_ids = input_ids.type(torch.IntTensor)\n","        # mask = mask.type(torch.IntTensor)\n","        # labels = labels.type(torch.LongTensor)\n","\n","\n","        input_ids = input_ids.to(DEVICE)\n","        mask = mask.to(DEVICE)\n","        token = token.to(DEVICE)\n","        \n","        loss = QA_model(input_ids, mask, token, SEPind, Start_pos, End_pos)\n","        \n","        # print(loss.item())\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        \n","        # correct_num = (Start_pred == Start_1hot).type(torch.int).sum()\n","        \n","        training_loss += loss.item()\n","\n","        # training_correct += correct\n","        \n","\n","    avg_loss = training_loss / len(train_loader)\n","\n","    H['train_loss'].append(avg_loss)\n","    # H['train_acc'].append(avg_correct)\n","    print(\"Train loss: {:.6f}\".format(avg_loss))\n","#"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-12T06:55:40.660570Z","iopub.status.busy":"2023-03-12T06:55:40.659852Z","iopub.status.idle":"2023-03-12T06:55:40.860983Z","shell.execute_reply":"2023-03-12T06:55:40.859826Z","shell.execute_reply.started":"2023-03-12T06:55:40.660527Z"},"id":"_1Q2pShetwv_","trusted":true},"outputs":[],"source":["# 繪製結果\n","\n","import matplotlib\n","import matplotlib.pyplot as plt\n","\n","# tensor to float\n","H['train_loss'] = [float(i) for i in H['train_loss']]\n","# H['train_acc'] = [float(i) for i in H['train_acc']]\n","# H['val_loss'] = [float(i) for i in H['val_loss']]\n","# H['val_acc'] = [float(i) for i in H['val_acc']]\n","\n","# loss\n","plt.figure()\n","plt.title(\"Loss\")\n","plt.xlabel(\"EPOCH\")\n","plt.ylabel(\"Loss\")\n","plt.plot(H[\"train_loss\"], label=\"test_loss\")\n","# plt.plot(H[\"val_loss\"], label=\"test_loss\")\n","plt.xticks(np.arange(EPOCH_NUM), range(1,EPOCH_NUM+1,1))\n","plt.show()\n","\n","# accuracy\n","# plt.figure()\n","# plt.title(\"Test Accuracy\")\n","# plt.xlabel(\"EPOCH\")\n","# plt.ylabel(\"Accuracy\")\n","# plt.plot(H[\"train_acc\"], label=\"test_acc\")\n","# # plt.plot(H[\"val_acc\"], label=\"test_acc\")\n","# plt.xticks(np.arange(6), range(1,7,1))\n","# plt.show()\n","\n"]}],"metadata":{"colab":{"provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":4}
