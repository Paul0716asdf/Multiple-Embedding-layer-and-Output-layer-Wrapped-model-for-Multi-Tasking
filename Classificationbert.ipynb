{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-03-12T06:12:42.707362Z","iopub.status.busy":"2023-03-12T06:12:42.706399Z","iopub.status.idle":"2023-03-12T06:12:42.719853Z","shell.execute_reply":"2023-03-12T06:12:42.718694Z","shell.execute_reply.started":"2023-03-12T06:12:42.707316Z"},"id":"DfPP69sn93Ee","trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","import torch\n","from transformers import BertTokenizer\n","from sklearn.utils import shuffle\n","\n","from typing import *\n","\n","from MEOW_Models import Classification_models, MT_models\n","from MEOW_Utils import Classification_utils, MT_utils\n","\n","DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","BATCH_SIZE = 4\n","EPOCH_NUM = 10\n","INPUT_FILE_PATH = r'C:\\Users\\Administrator\\codeblocks_workspace\\MEOW\\Sentiment_train.csv'\n","PRETRAINED_MODULE_NAME = 'bert-base-uncased'"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>context</th>\n","      <th>label</th>\n","      <th>label_name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>11397</th>\n","      <td>IÂm getting personal... IÂm not one to allow...</td>\n","      <td>4</td>\n","      <td>Extremely Negative</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                 context  label  \\\n","11397  IÂm getting personal... IÂm not one to allow...      4   \n","\n","               label_name  \n","11397  Extremely Negative  "]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODULE_NAME)\n","train_df = MT_utils.get_Sentiment_df(INPUT_FILE_PATH)\n","num_labels = len(train_df.value_counts('label').keys())\n","train_df.sample(8)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>context</th>\n","      <th>label</th>\n","      <th>label_name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>What are my rights with event/travel cancellat...</td>\n","      <td>1</td>\n","      <td>Positive</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>@FrischepostHH delivers food to front door, of...</td>\n","      <td>2</td>\n","      <td>Neutral</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>GREAT NEWS!\\r\\r\\n\\r\\r\\nREDUCED PRICES DUE TO #...</td>\n","      <td>0</td>\n","      <td>Extremely Positive</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>National #supermarket chains have failed the #...</td>\n","      <td>4</td>\n","      <td>Extremely Negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>How is your business adapting to #COVID19? Can...</td>\n","      <td>0</td>\n","      <td>Extremely Positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                             context  label  \\\n","0  What are my rights with event/travel cancellat...      1   \n","1  @FrischepostHH delivers food to front door, of...      2   \n","2  GREAT NEWS!\\r\\r\\n\\r\\r\\nREDUCED PRICES DUE TO #...      0   \n","3  National #supermarket chains have failed the #...      4   \n","4  How is your business adapting to #COVID19? Can...      0   \n","\n","           label_name  \n","0            Positive  \n","1             Neutral  \n","2  Extremely Positive  \n","3  Extremely Negative  \n","4  Extremely Positive  "]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["train_df.head()"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertWithoutEmbedding: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertWithoutEmbedding from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertWithoutEmbedding from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["bert_model = MT_models.BertWithoutEmbedding.from_pretrained(PRETRAINED_MODULE_NAME)\n","GETEMBEDDING_helper = MT_utils.get_bert_element(bertmodel=bert_model)\n","embedding_layer = GETEMBEDDING_helper.get_copy_embeddings_layer()\n","\n","train_dataset = Classification_utils.Classification_dataset(df = train_df, tokenizer = tokenizer, num_labels=num_labels)\n","train_loader = Classification_utils.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=Classification_utils.collate_batch)\n","\n","Classification_model = Classification_models.Bert_classification(model=bert_model, embedding_layer=embedding_layer, device=DEVICE, num_labels=num_labels)\n","Classification_model.to(DEVICE)\n","\n","optimizer = torch.optim.SGD(Classification_model.parameters(), lr=0.0001, momentum=0.9)\n","# optimizer = torch.optim.Adam(QA_model.parameters(), lr=0.001, betas=(0.88, 0.95), eps=1e-08)\n","\n","H = {\n","    \"train_loss\": [],\n","    \"train_acc\": [],\n","    \"val_loss\":[],\n","    \"val_acc\": []\n","    }"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(tensor([  101,  2002,  2003,  6951,  2075,  2061,  2515,  2008,  3084,  2009,\n","         3100,  1029,  2054,  2055, 13025,  3573, 26706,  1010, 11500,  1010,\n","         7435,  1998, 13882,  3095,  1029,  2358,  8516,  2923,  2035,  2058,\n","         2024,  2701,  1012,  2339,  2003,  6951,  2075,  3100,  1029,  2064,\n","         1045,  2330,  2039,  2007, 11875,  1998,  7308,  1029,  1001,  2994,\n","         8988,  8462,  1001, 21887, 23350,  1001,  2522, 17258,  1001, 26629,\n","         1001,  2606, 16770,  1024,  1013,  1013,  1056,  1012,  2522,  1013,\n","        16731,  2890, 17922,  2549,  2100, 23644,   102]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0]), [0.0, 1.0])\n"]}],"source":["print(train_dataset[0])"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"execution":{"iopub.execute_input":"2023-03-12T07:35:23.943599Z","iopub.status.busy":"2023-03-12T07:35:23.942880Z","iopub.status.idle":"2023-03-12T07:36:54.746340Z","shell.execute_reply":"2023-03-12T07:36:54.745130Z","shell.execute_reply.started":"2023-03-12T07:35:23.943552Z"},"id":"ANXk7YP4BeuB","outputId":"1c8fdf98-cfcd-44e9-d6f5-6df336f63d9a","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["the 1 iter :\n"]},{"ename":"IndexError","evalue":"list assignment index out of range","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32mc:\\Users\\Administrator\\codeblocks_workspace\\MEOW\\Classificationbert.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Administrator/codeblocks_workspace/MEOW/Classificationbert.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m training_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Administrator/codeblocks_workspace/MEOW/Classificationbert.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m training_correct \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Administrator/codeblocks_workspace/MEOW/Classificationbert.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Administrator/codeblocks_workspace/MEOW/Classificationbert.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     input_ids, mask, token, label \u001b[39m=\u001b[39m data\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Administrator/codeblocks_workspace/MEOW/Classificationbert.ipynb#W4sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39m# input_ids = input_ids.type(torch.IntTensor)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Administrator/codeblocks_workspace/MEOW/Classificationbert.ipynb#W4sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m# mask = mask.type(torch.IntTensor)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Administrator/codeblocks_workspace/MEOW/Classificationbert.ipynb#W4sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39m# labels = labels.type(torch.LongTensor)\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    679\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 681\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    684\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    685\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    719\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    720\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 721\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    722\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    723\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n","File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[1;32mc:\\Users\\Administrator\\codeblocks_workspace\\MEOW\\MEOW_Utils\\Classification_utils.py:58\u001b[0m, in \u001b[0;36mClassification_dataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     56\u001b[0m token \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(EC[\u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     57\u001b[0m label \u001b[39m=\u001b[39m [\u001b[39m0.\u001b[39m] \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_labels\n\u001b[1;32m---> 58\u001b[0m label[df[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m][index]] \u001b[39m=\u001b[39m \u001b[39m1.\u001b[39m\n\u001b[0;32m     60\u001b[0m \u001b[39mreturn\u001b[39;00m input_ids, mask, token, label\n","\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"]}],"source":["for epoch in range(EPOCH_NUM):\n","    print(\"the {:d} iter :\".format(epoch+1))\n","\n","    Classification_model.train()\n","    # train \n","    training_loss = 0.0\n","    training_correct = 0.0\n","\n","    for data in train_loader:\n","        input_ids, mask, token, label = data\n","        \n","        # input_ids = input_ids.type(torch.IntTensor)\n","        # mask = mask.type(torch.IntTensor)\n","        # labels = labels.type(torch.LongTensor)\n","\n","        input_ids = input_ids.to(DEVICE)\n","        mask = mask.to(DEVICE)\n","        token = token.to(DEVICE)\n","        label = label.to(DEVICE)\n","    \n","        outputs = Classification_model(input_ids, token=token, attention_mask=mask, label=label )\n","        loss = outputs[0]\n","        prob = outputs[1]\n","\n","        print(loss)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        predict = torch.argmax(prob, dim=1)\n","        label = torch.argmax(label, dim=1)\n","        correct_num = (predict == label).type(torch.int).sum()\n","        \n","        training_loss += loss.item()\n","        training_correct += correct_num\n","        \n","        # print(correct_num)\n","        \n","\n","    avg_loss = training_loss / len(train_loader)\n","    avg_acc = training_correct / len(train_dataset)\n","\n","    H['train_loss'].append(avg_loss)\n","    H['train_acc'].append(avg_acc)\n","    print(\"Train loss: {:.6f}, Train accuracy {:.4f}\".format(avg_loss, avg_acc))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-12T06:55:40.660570Z","iopub.status.busy":"2023-03-12T06:55:40.659852Z","iopub.status.idle":"2023-03-12T06:55:40.860983Z","shell.execute_reply":"2023-03-12T06:55:40.859826Z","shell.execute_reply.started":"2023-03-12T06:55:40.660527Z"},"id":"_1Q2pShetwv_","trusted":true},"outputs":[],"source":["import matplotlib\n","import matplotlib.pyplot as plt\n","\n","# tensor to float\n","H['train_loss'] = [float(i) for i in H['train_loss']]\n","# H['train_acc'] = [float(i) for i in H['train_acc']]\n","\n","# H['val_loss'] = [float(i) for i in H['val_loss']]\n","# H['val_acc'] = [float(i) for i in H['val_acc']]\n","\n","# loss\n","plt.figure()\n","plt.title(\"Loss\")\n","plt.xlabel(\"EPOCH\")\n","plt.ylabel(\"Loss\")\n","plt.plot(H[\"train_loss\"], label=\"test_loss\")\n","# plt.plot(H[\"val_loss\"], label=\"test_loss\")\n","plt.xticks(np.arange(10), range(1,11,1))\n","plt.show()\n","\n","# accuracy\n","# plt.figure()\n","# plt.title(\"Test Accuracy\")\n","# plt.xlabel(\"EPOCH\")\n","# plt.ylabel(\"Accuracy\")\n","# plt.plot(H[\"train_acc\"], label=\"test_acc\")\n","# # plt.plot(H[\"val_acc\"], label=\"test_acc\")\n","# plt.xticks(np.arange(6), range(1,7,1))\n","# plt.show()\n","\n"]}],"metadata":{"colab":{"provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":4}
